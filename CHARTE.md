# LE CODE VAUT LOI

## Charte pour la légitimité démocratique des systèmes numériques

---

## Table des matières

1. [Préambule](#préambule)
2. [Article 1 — Du principe](#article-1--du-principe)
3. [Article 2 — De la transparence](#article-2--de-la-transparence)
4. [Article 3 — Du code](#article-3--du-code)
5. [Article 4 — De la publicité du code](#article-4--de-la-publicité-du-code)
6. [Article 5 — Des audits](#article-5--des-audits)
7. [Article 6 — De la preuve](#article-6--de-la-preuve)
8. [Article 7 — De l'opacité](#article-7--de-lopacité)
9. [Article 8 — De la souveraineté](#article-8--de-la-souveraineté)
10. [Article 9 — Du consentement](#article-9--du-consentement)
11. [Article 10 — Du droit d'accès](#article-10--du-droit-daccès)
12. [Article 11 — Du droit de refus](#article-11--du-droit-de-refus)
13. [Article 12 — De l'exigence](#article-12--de-lexigence)
14. [Dispositions finales](#dispositions-finales)

---

## Préambule

Les institutions européennes et nationales déploient des systèmes numériques qui régissent l'ensemble de notre société démocratique. Elles exigent que nous, citoyens, leur fassions confiance.

Cette confiance ne peut être accordée par décret, ni imposée par la loi. Elle se mérite par la transparence, se vérifie par l'audit, et se maintient par la preuve.

La présente charte établit les conditions minimales sous lesquelles un système numérique peut prétendre à la légitimité démocratique.

---

## Article 1 — Du principe

**Le système n'est légitime que s'il est vérifiable. Toute autorité qui ne peut être auditée est réputée illégitime.**

### 1.1 Fondements juridiques

| Source | Texte |
|--------|-------|
| **Article 15 DDHC 1789** | *« La société a le droit de demander compte à tout agent public de son administration. »* |
| **Article 14 DDHC** | *« Tous les citoyens ont le droit de constater, par eux-mêmes ou par leurs représentants, la nécessité de la contribution publique, de la consentir librement, d'en suivre l'emploi. »* |
| **CC, n°2018-765 DC** | Le principe d'intelligibilité et d'accessibilité de la loi découle des articles 4, 5, 6 et 16 de la DDHC. |

### 1.2 Principe posé

Les systèmes numériques déployés par l'État ou imposés aux citoyens constituent une forme d'administration. À ce titre, ils sont soumis au même impératif de redevabilité que tout agent public. 

Un système dont le fonctionnement ne peut être examiné échappe par construction au contrôle démocratique. L'impossibilité technique de l'audit équivaut à un refus politique de rendre des comptes.

### 1.3 Champ d'application

- Portefeuilles d'identité numérique (EUDI Wallet, France Identité)
- Systèmes de vérification d'identité imposés par la loi (ARCOM, loi SREN)
- Algorithmes de modération des plateformes désignées par le DSA
- Systèmes de notation, scoring ou profilage utilisés par les administrations (ParcourSup, Impots.gouv)
- Tout système conditionnel à l'accès à un service public ou un droit (France Travail, URSSAF)

---

## Article 2 — De la transparence

**La transparence n'est pas une option, ni une promesse. Elle constitue la condition minimale de la confiance.**

### 2.1 Fondements juridiques

| Source | Texte |
|--------|-------|
| **Article 6 DDHC** | *« La loi est l'expression de la volonté générale. »* — Une volonté ne peut s'exprimer sur ce qu'elle ne peut connaître. |
| **Article 10 CEDH** | Liberté de recevoir et de communiquer des informations. |
| **Loi n°78-753** (loi CADA) | Droit d'accès aux documents administratifs. |
| **Règlement (UE) 2022/868** (DGA), considérant 5 | *« La confiance dans les services de données est essentielle. »* |

### 2.2 Principe posé

La transparence ne peut être réduite à une déclaration d'intention ni à une politique de communication. Elle exige la possibilité matérielle, pour tout citoyen ou expert mandaté, d'examiner le fonctionnement réel d'un système. 

Une transparence promise mais techniquement impossible est une transparence fictive. 

Une transparence partielle (documentation sans code, audits sans publication) est une transparence de façade.

### 2.3 Champ d'application

- Documentation technique des systèmes d'identité numérique
- Politiques de modération des plateformes soumises au DSA
- Algorithmes de recommandation et de ciblage publicitaire
- Critères de décision automatisée dans les administrations (CAF, France Travail)
- Tout système dont l'usage est obligatoire ou quasi-obligatoire (ParcourSup, Impots.gouv)

---

## Article 3 — Du code

**Le code est une norme exécutable. Lorsqu'il régit des droits, des devoirs ou des services publics, il vaut loi.**

### 3.1 Fondements juridiques

| Source | Texte |
|--------|-------|
| **Article 34 Constitution** | La loi fixe les règles concernant les droits civiques et les garanties fondamentales accordées aux citoyens. |
| **CE, rapport 2017** | "Puissance publique et plateformes numériques" : Reconnaissance que les algorithmes peuvent constituer des normes de fait. |
| **Règlement (UE) 2024/1689** (AI Act), art. 14 | Exigence de contrôle humain sur les systèmes d'IA à haut risque. |
| **CNIL, n°2018-155** | Les décisions automatisées produisent des effets juridiques. |

### 3.2 Principe posé

Lorsqu'un programme informatique détermine l'accès à un droit, l'attribution d'une prestation, la possibilité de s'exprimer ou la vérification d'une identité, il exerce une fonction normative. 

Le code n'est plus alors un simple outil technique : il devient la loi effective, celle qui s'applique réellement. À ce titre, il doit être soumis aux mêmes exigences de publicité, d'intelligibilité et de contestabilité que toute norme juridique.

### 3.3 Champ d'application

- Algorithmes déterminant l'accès aux prestations sociales
- Systèmes de vérification d'âge bloquant l'accès à des contenus
- Filtres de modération automatique sur les plateformes
- Scoring utilisé pour les décisions administratives (fraude, risque, allocation)
- Smart contracts ayant des effets juridiques sur les personnes

---

## Article 4 — De la publicité du code

**Tout code — client et serveur — des plateformes de services publics, des systèmes d'identité numérique et des dispositifs de vérification doit être intégralement public, accessible et lisible.**

### 4.1 Fondements juridiques

| Source | Texte |
|--------|-------|
| **Loi n°2016-1321**, art. 2 | Les administrations publient en ligne les règles définissant les principaux traitements algorithmiques. |
| **CRPA, art. L.311-3-1** | Droit à communication des règles algorithmiques individuelles. |
| **Directive (UE) 2019/1024** (Open Data) | Principe de réutilisation des données et documents du secteur public. |
| **CJUE, C-252/21** (Meta Platforms) | L'effectivité des droits implique l'accès aux mécanismes qui les affectent. |

### 4.2 Principe posé

L'exigence de publicité de la loi s'étend à ses instruments d'exécution. Un code non public est une loi secrète. 

La publication du seul code client (front-end) est insuffisante : c'est dans le code serveur (back-end) que résident les décisions réelles. 

La lisibilité implique non seulement l'accès au code source, mais aussi à sa documentation, ses dépendances, ses configurations et ses données d'entraînement le cas échéant.

### 4.3 Champ d'application

- Application France Identité et infrastructure EUDI Wallet
- Systèmes de vérification d'âge certifiés par l'ARCOM
- Algorithmes de modération des plateformes désignées (DSA)
- Interfaces de programmation (API) des services publics numériques
- Tout dispositif technique dont l'usage conditionne l'exercice d'un droit

---

## Article 5 — Des audits

**Les audits doivent être ouverts, complets, indépendants, réguliers et publiquement accessibles. Un audit confidentiel est réputé nul.**

### 5.1 Fondements juridiques

| Source | Texte |
|--------|-------|
| **Règlement (UE) 2022/2065** (DSA), art. 37 et 40 | Audits indépendants obligatoires pour les très grandes plateformes. |
| **Règlement (UE) 2024/1689** (AI Act), art. 43 | Évaluation de conformité par des organismes notifiés. |
| **Cour des comptes, rapport 2020** | Nécessité d'audits des algorithmes publics. |
| **ISO 27001 / ISO 42001** | Standards d'audit des systèmes d'information et d'intelligence artificielle. |

### 5.2 Principe posé

Un audit n'a de valeur que s'il peut être vérifié. 

Un audit dont les conclusions sont publiées mais dont la méthode, le périmètre et les données restent confidentiels ne permet aucun contre-examen. Il constitue un argument d'autorité, non une preuve. 

L'indépendance de l'auditeur doit être structurelle (absence de lien commercial ou hiérarchique) et non simplement déclarée. 

La régularité des audits doit être proportionnée à la criticité du système.

### 5.3 Champ d'application

- Plateformes désignées au titre du DSA (VLOP, VLOSE)
- Systèmes d'IA à haut risque au sens de l'AI Act
- Systèmes d'identité numérique nationaux et européens
- Dispositifs de vérification d'âge certifiés
- Algorithmes publics listés par chaque administration (obligation loi République numérique)

---

## Article 6 — De la preuve

**La confiance ne se déclare pas. Elle se démontre par les faits, le code et l'audit.**

### 6.1 Fondements juridiques

| Source | Texte |
|--------|-------|
| **Code civil, art. 1353** | *« Celui qui réclame l'exécution d'une obligation doit la prouver. »* |
| **Principe général du droit** | *Actori incumbit probatio* — la charge de la preuve incombe à celui qui allègue. |
| **RGPD, art. 5.2** | Principe d'accountability — le responsable du traitement doit être en mesure de démontrer la conformité. |
| **AI Act, art. 11** | Obligation de documentation technique démontrant la conformité. |

### 6.2 Principe posé

L'État ou la plateforme qui déploie un système et exige qu'on lui fasse confiance supporte la charge de prouver que cette confiance est justifiée. 

Cette preuve ne peut consister en une simple déclaration, une certification opaque ou un label auto-attribué. Elle doit être matériellement vérifiable par des tiers indépendants et par les citoyens eux-mêmes. 

L'inversion de la charge de la preuve — demander au citoyen de prouver l'abus plutôt qu'au système de prouver sa fiabilité — est contraire aux principes fondamentaux du droit.

### 6.3 Champ d'application

- Certifications de conformité RGPD, DSA, AI Act
- Labels de confiance des systèmes d'identité numérique
- Déclarations de sécurité des dispositifs de vérification
- Allégations de neutralité des algorithmes de recommandation
- Toute affirmation de fiabilité, sécurité ou respect des droits

---

## Article 7 — De l'opacité

**L'opacité constitue une faute systémique. Tout mécanisme non documenté ou non auditable est présumé abusif.**

### 7.1 Fondements juridiques

| Source | Texte |
|--------|-------|
| **RGPD, art. 12** | Les informations doivent être fournies *« de façon concise, transparente, compréhensible et aisément accessible »*. |
| **CJUE, C-634/21** (SCHUFA) | Le profilage opaque affectant significativement les personnes est contraire au RGPD. |
| **CC, n°99-421 DC** | L'objectif d'intelligibilité de la loi a valeur constitutionnelle. |
| **CRPA, art. L.311-3-1** | Droit d'obtenir la communication des règles algorithmiques. |

### 7.2 Principe posé

L'opacité n'est pas un état neutre. Dans un système qui affecte les droits des personnes, elle constitue en soi un manquement. 

L'impossibilité d'examiner un mécanisme interdit de vérifier s'il est conforme au droit, équitable, non discriminatoire. 

En l'absence de preuve contraire, un système opaque doit être présumé potentiellement abusif. Cette présomption n'est pas une accusation mais une conséquence logique de l'impossibilité de vérifier.

### 7.3 Champ d'application

- Algorithmes de scoring et de notation (crédit, assurance, fraude)
- Systèmes de modération automatique non explicités
- Critères de ciblage publicitaire non documentés
- Mécanismes de recommandation dont les paramètres sont secrets
- Toute boîte noire ayant des effets sur les droits ou libertés

---

## Article 8 — De la souveraineté

**La souveraineté ne se proclame pas : elle s'exécute. Un système fermé ne peut prétendre à la légitimité démocratique.**

### 8.1 Fondements juridiques

| Source | Texte |
|--------|-------|
| **Constitution, art. 3** | *« La souveraineté nationale appartient au peuple. »* |
| **CC, n°2006-540 DC** | La transposition de directives européennes ne peut priver de garanties constitutionnelles. |
| **CJUE, Schrems II** | Les transferts de données vers des pays tiers doivent garantir un niveau de protection équivalent. |
| **Règlement (UE) 2024/1183** (eIDAS 2.0) | Reconnaissance mutuelle des identités numériques entre États membres. |

### 8.2 Principe posé

La souveraineté numérique invoquée par les États ne peut se réduire à la localisation des serveurs ou à la nationalité des prestataires. Elle exige que les citoyens puissent effectivement contrôler les systèmes qui les gouvernent. 

Un système développé par des acteurs nationaux mais dont le code est fermé n'est pas plus souverain qu'un système étranger : dans les deux cas, le citoyen est dépossédé. 

La souveraineté réelle est celle du peuple sur les instruments de son administration.

### 8.3 Champ d'application

- Systèmes d'identité numérique présentés comme "souverains"
- Clouds qualifiés SecNumCloud mais au code propriétaire
- Solutions de vérification d'âge développées par des acteurs nationaux
- Infrastructures critiques numériques de l'État
- Tout système invoquant la souveraineté pour justifier son déploiement

---

## Article 9 — Du consentement

**Nul ne peut être soumis à un système qu'il ne peut examiner. Le consentement sans accès au code est un consentement vicié.**

### 9.1 Fondements juridiques

| Source | Texte |
|--------|-------|
| **RGPD, art. 4.11** | Le consentement doit être *« libre, spécifique, éclairé et univoque »*. |
| **RGPD, art. 7** | Le responsable du traitement doit être en mesure de démontrer que la personne a consenti. |
| **Code civil, art. 1130 et s.** | Le consentement vicié par l'erreur, le dol ou la violence est nul. |
| **Directive 93/13/CEE** | Les clauses abusives dans les contrats avec les consommateurs sont réputées non écrites. |

### 9.2 Principe posé

Le consentement exigé par le RGPD suppose une information complète sur ce à quoi l'on consent. Consentir à l'usage d'un système dont on ne peut connaître le fonctionnement réel est une contradiction dans les termes. 

Le consentement éclairé suppose l'accès non seulement aux finalités déclarées mais aux moyens effectifs. 

Un consentement obtenu sans cette possibilité d'examen est juridiquement vicié : il repose sur une information incomplète qui s'apparente à une erreur provoquée.

### 9.3 Champ d'application

- Acceptation des conditions d'utilisation des plateformes
- Consentement aux traitements d'identité numérique
- Accord aux dispositifs de vérification d'âge
- Opt-in aux systèmes de personnalisation algorithmique
- Tout consentement conditionnel à l'accès à un service essentiel

---

## Article 10 — Du droit d'accès

**Tout citoyen dispose d'un droit d'accès complet aux mécanismes qui le concernent. Ce droit s'applique aux données personnelles, au code qui les traite, aux algorithmes qui les évaluent, et aux décisions qui en découlent.**

### 10.1 Fondements juridiques

| Source | Texte |
|--------|-------|
| **RGPD, art. 15 et 22** | Droit d'accès aux données et droit de ne pas faire l'objet d'une décision entièrement automatisée. |
| **Loi IL, art. 47** | Droit d'obtenir une intervention humaine et de contester la décision. |
| **CRPA, art. L.311-3-1** | Communication des règles algorithmiques individuelles. |
| **AI Act, art. 86** | Droit d'obtenir des explications sur les décisions des systèmes d'IA à haut risque. |

### 10.2 Principe posé

Le droit d'accès aux données personnelles, consacré depuis 1978, est devenu insuffisant. Connaître ses données sans comprendre comment elles sont utilisées est un droit tronqué. 

L'accès doit s'étendre au code source qui traite ces données, aux modèles algorithmiques qui les évaluent, aux critères qui produisent les décisions, et à la logique qui sous-tend les résultats. 

Ce droit d'accès étendu est la condition d'un droit de recours effectif.

### 10.3 Champ d'application

- Décisions automatisées des administrations (prestations, contrôles, sanctions)
- Scoring et notation par les entreprises (crédit, assurance, emploi)
- Modération et déréférencement sur les plateformes
- Recommandations algorithmiques personnalisées
- Toute décision ou proposition ayant un effet significatif sur la personne

---

## Article 11 — Du droit de refus

**Nul ne peut être contraint d'utiliser un système qu'il ne peut examiner ou qu'il juge illégitime. L'alternative non-numérique constitue un droit fondamental, non une tolérance provisoire. Tout service conditionné à l'usage exclusif d'un système opaque est réputé discriminatoire.**

### 11.1 Fondements juridiques

| Source | Texte |
|--------|-------|
| **Constitution, art. 1er** | La République *« assure l'égalité devant la loi de tous les citoyens »*. |
| **Défenseur des droits, rapport 2019** | La dématérialisation ne doit pas créer de discrimination dans l'accès aux droits. |
| **Loi n°2016-1321, art. 3** | Droit au maintien de la connexion pour les services essentiels. |
| **CEDH, art. 14** | Interdiction de discrimination dans la jouissance des droits. |
| **CRPA, art. L.112-8** | Droit de saisir l'administration par voie électronique, non obligation. |

### 11.2 Principe posé

L'alternative non-numérique n'est pas une concession aux "retardataires" mais une garantie démocratique. 

Conditionner l'accès à un droit ou un service à l'utilisation d'un système que le citoyen ne peut pas examiner ou qu'il considère illégitime revient à lui imposer une sujétion sans recours. 

Le droit de refuser un système opaque est le corollaire nécessaire du droit de contrôle. Un État qui supprime les alternatives contraint de fait à l'obéissance aveugle.

### 11.3 Champ d'application

- Démarches administratives exclusivement dématérialisées
- Services publics accessibles uniquement via identité numérique
- Plateformes sans possibilité de refuser la vérification algorithmique
- Services bancaires ou d'assurance exigeant des applications propriétaires
- Tout service essentiel conditionné à l'acceptation d'un système invérifiable

---

## Article 12 — De l'exigence

**Un système digne de confiance n'a rien à cacher. Un système qui cache n'a rien à exiger.**

### 12.1 Fondements juridiques

| Source | Texte |
|--------|-------|
| **Principe de proportionnalité** | Reconnu par le Conseil constitutionnel, la CJUE et la CEDH comme principe général du droit. |
| **CEDH, art. 8** | Le droit au respect de la vie privée ne peut être limité que par des mesures *« nécessaires dans une société démocratique »*. |
| **RGPD, art. 5.1.c** | Principe de minimisation des données. |
| **AI Act, considérant 47** | Les exigences imposées aux utilisateurs doivent être proportionnées aux risques. |

### 12.2 Principe posé

L'asymétrie actuelle est intenable : l'État et les plateformes exigent une transparence totale du citoyen (identité, âge, données biométriques, comportements) tout en maintenant l'opacité de leurs propres systèmes. Cette inversion du rapport démocratique ne peut fonder aucune légitimité. 

L'exigence de transparence du citoyen ne peut excéder celle que le système s'impose à lui-même. Un système qui refuse de se montrer n'est pas fondé à exiger qu'on se montre à lui.

### 12.3 Champ d'application

- Systèmes de vérification d'identité exigeant des données biométriques
- Dispositifs de vérification d'âge demandant des pièces d'identité
- Plateformes exigeant une identification complète pour l'accès
- Administrations demandant des informations sans justifier leurs algorithmes
- Tout système créant une asymétrie d'information au détriment du citoyen

---

## Dispositions finales

La présente charte n'a pas vocation à remplacer le droit existant mais à en rappeler les exigences et à en étendre la portée aux réalités numériques. Elle constitue un instrument d'évaluation : tout système qui ne satisfait pas à ses conditions ne peut prétendre à la confiance des citoyens ni à la légitimité démocratique.

Elle invite les législateurs à traduire ces principes en obligations contraignantes, les juridictions à les invoquer dans leur interprétation du droit, et les citoyens à les revendiquer comme standards minimaux de l'État de droit numérique.

---

*Document rédigé dans la tradition du libéralisme politique français, de Tocqueville à Aron, qui reconnaît que la liberté ne se préserve que par la vigilance institutionnelle et le refus de l'arbitraire, fût-il technologique.*

*Contributeurs (à compléter) : Jérôme Bourreau-Guggenheim*
